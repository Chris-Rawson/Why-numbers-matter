# Reading corellations can be baffling for the uninitiated, but once you have your head around them they are very handly little calculations.

A bi-variate, or Pearson's, correlation is a formula that maps out how closely two variables move together.   

There's often written with an r value, and a p value in brackets.  For example, r=0.684 (p=>001).

But what on earth does that mean?


### Correlation coefficient

The r value represents the 'correlation coefficient.'

The correlation coefficient is an indication of the strenth of the relationship between two variables.

Remember [a few steps back](link), we introduced a study of [the effectivenss of software to teach fractions to sixth-graders](http://scholarcommons.usf.edu/cgi/viewcontent.cgi?article=1129&context=numeracy)?

One way that we could figure out its effectiveness might be to test the hypothesis that the greater the amount of the time sixth-graders use educational software to learn fractions, the higher their test scores will be graded.

In this hypothesis, there are two variables: time spent using the software, and test scores.  If the test scores go up together, we can be pretty confident that there's a positive correlation. If there tests scores actually go _further down_ the longer they play the game, then we can be confident in a negative correlation.   

The __r value__, or correlation coefficient, that how strong this correlation is.  In other words, how closely do they vary together.

An r value is always between -1, which means there's an ironclad negative correlation, or 1, which means the opposite.  In other words, if we had an r value of 1, we know that the amount of time that students spend with the software _always_ has a direct positive impact on their test results, and for -1 vice-versa.

Squaring your r value might make it easier to understand.  An r of .5 means 25% of the variation is related (.5 squared =.25). An r value of .7 means 49% of the variance is related (.7 squared = .49).

Another way to understand it is to visualise it with the help of a scatter plot.  To make one, we'd put test scores on the vertical y axis, and time on the x (convention dictates that the dependent variable should go on the y axis).  If you plotted, or put a little dot on the graph, each student's test score and the time they'd spent using the software:

* a correlation on 1 would go in a straight up in line from bottom left to top right. 
* a correlation of 0.5 would trend upwards, but not in a straight line
* a correlation of 0 would show random dots everywhere

Scatterplots of negative correlations would be a mirror image of these ones.

[!insert graphs demonstrating this from left to right of screen.]


### Descriptions of the correlation coefficient.

You might sometimes come across a description of a correlation coefficient that's described in words rather than numbers.  There are conventions for these too, so it's worth knowing how the words relate to the numbers:

| __R value__  | __Description__ |
| 0.5 - 1 |  Strong positive correlation |
| 0.3 - 0.5	  | Moderate positive correlation |
| 0.1 - 0.3 | Weak positive correlation|

Again, we'd see a mirror of these descriptions for negative correlations.

How 'good' a result is really depends on the context of your research project.  That being said, if you wanted to show that your software improved test scores over time, you'd usually need to find a correlation of above 0.5 to get other researchers all that interested.  Add in a control group which shows a weaker, or no, correlation and you would think that other researchers would start pushing for its adopting in schools.

By the way, these correlations are usually employed for parametric data, or data that fits with normal distribution.  






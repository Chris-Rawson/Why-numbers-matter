## Confidence intervals tell us how close our sample average is likely to be to the average of our population.

## Confidence

You might recall that in [the previous step](link), one woman managed 149 pushups in under two minutes. Considering that the average number was only 74.3 pushups, that's pretty extraordinaty.  In fact, using standard deviation, we were able to determine that there was less than 0.3% probability of that occuring in our sample. Probably enough to wonder if it's too good to be true.

Thankfully, standard deviation can give an indication if our measurements are wrong. For example, if a person was recorded as having done 181 pushups, the that person is 106.7 pushups above the mean (181 - 74.3).  Given that standard deviation was 24.7, that is a whopping 4.3 standard deviations away from the mean (106 / 24.7).  

The probability of that occuring is [less than 0.001%](http://www.bmj.com/sites/default/files/attachments/resources/2011/08/appendix-table.pdf).  In most circumstances, faced with that, statistitians would assume that an error had been made and exclude them from their analysis.

In case you're wondering, our push-upper who was recorded at 148 is 2.98 standard deviations from the mean, giving her less than a 0.01% probability of being legit.  Not impossible, but unless you've got video evidence, you might want to test her again.

## Confidence intervals

While we can be certain about these figures in our our _own_ sample, how confident can you be that it will be replicated in the target population?

To find out, you need to calculate your confidence interval.

Your confidence interval will tell you how confident you can be that the average, and the differences, in your sample are similar to your population.  Or, to be more specific, how confident you can be that if you did the same test on your whole population that you would get the same mean and distribution as you did from your sample.

To be sure of your results, you'd want to decide on how much uncertainty you're prepared to tolerate. Usually, you'd exclude results that are over two standard deviations from your mean.  The reasons for doing so are technical, but this means that you can be 95% certain that your results are realistic. 

That is to say, if you were to test the sample the target population again you can be 95% sure of getting the results in that range again, assuming that your measurements have been consistently accurate.

## The calculations

Thankfully,  calculating where a result falls withing a 95% confidence interval is exceptionally simple.

Simply add 1.96 times the standand deviation to the mean to find your ceiling, and subtract the same to find your floor.  You might consider excluding any results outside those boundaries.

For example, for our push-uppers we'd find our:

* __upper limit__ 74.3 + (1.96 x 24.7) = 122
* __lower limit__ 74.3 - (1.96 x 24.7) = 25.8


One last thing to mention.  If you have been using ratio data [introduce ratios into types of data], you will need to calculate your confidence intervals a little bit differently.  You could use [this online calculator](https://www.graphpad.com/quickcalcs/ErrorProp1.cfm) - [add in section about decifering crazy notation], or otherwise consider speaking to an expert.

## Your task

something about renormalisation and intelligence?
